---
title: "âœ¨ LLM Chat Bot"
slug: "llm-chat-bot"
url: "https://github.com/AdamDCosta/chat-streaming-example"
image: "/images/chat-streaming-example.png"
stack: ["Nuxt", "Typescript", "OpenAI", "Tailwind"]
---

This is a minimal LLM chatbot built with Nuxt. Created to provide examples for my [blog](/blogs/streaming-llm-chat-responses) on streaming ai responses from a server to a client.

I've used VueJS professionally for a few years now, but never with Nuxt. I enjoyed the experience, particularly having a server setup ready to go. This meant I could build the project quickly and focus on the core functionality I wanted to introduce - server-sent-events, event sourcing and generator functions.
